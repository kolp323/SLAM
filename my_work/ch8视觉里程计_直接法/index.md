
《视觉SLAM十四讲》第八讲：直接法视觉里程计——初学者深度学习笔记


I. 引言：视觉里程计与直接法的核心理念

在移动机器人和自动驾驶等自主化设备（AuT）的研发中，同步定位与建图（SLAM）技术扮演着至关重要的角色。视觉SLAM作为SLAM的一个重要分支，通过分析相机图像信息来估计自身位姿并构建环境地图。在视觉SLAM的整个框架中，视觉里程计（Visual Odometry, VO）是不可或缺的“前端”组成部分，它为后续的优化和建图提供了基础数据。

A. 视觉里程计（VO）在SLAM中的作用与定位

视觉里程计（VO），常被称为SLAM的“前端”，其核心功能在于估算相邻图像帧之间相机的运动，并初步恢复局部场景的结构信息 1。通过连续分析相机捕获的图像序列，VO能够跟踪图像中的关键点，并运用三角测量算法来确定这些关键点的三维位置，同时利用这些三维点的信息来逼近相机自身的姿态 1。
VO之所以被称为“里程计”，是因为它专注于计算相机在相邻时刻之间的相对运动，而不直接考虑更早的历史信息或全局一致性 1。这种局部性使得VO能够以较高的频率提供位姿估计，满足移动机器人和自动驾驶系统对实时性的要求 4。通过将这些相邻时刻的运动估计串联起来，就可以逐步构建出机器人的运动轨迹，从而初步解决自身的定位问题 1。同时，根据每一时刻相机所估计的位置，可以计算出对应像素在三维空间中的位置，进而形成一个局部的环境地图 1。
VO作为SLAM系统的基石，其作用不仅限于提供初始的位姿估计。它为整个SLAM系统提供了高频率、连续的局部运动信息和场景结构数据 1。这种局部运动的准确性直接影响到后续全局优化和回环检测的效率与精度。VO的局部性使其计算效率相对较高，能够满足实时应用的需求。然而，这种局部性也意味着VO的估计会随着时间累积误差，形成“漂移”。因此，VO提供的初始、高频、局部位姿估计，需要由SLAM的后端优化和回环检测模块进行全局修正和精化 1。VO在定位与建图之间存在着紧密的相互作用。它不仅估计相机的运动（定位），还恢复场景的三维结构（建图） 1。这种内在的“同步”特性，即使在前端层面也得到了体现。定位的准确性直接影响着构建地图的精度，而一个鲁棒、精确的三维地图反过来又能为更准确的位姿估计提供支持。这种相互依赖的递归关系，正是SLAM核心挑战与内在精妙之处的体现。

B. 特征点法视觉里程计的局限性回顾

传统的视觉里程计方法，即特征点法，通过识别并跟踪图像序列中特定“点特征”的几何位置变化来估计相机的位姿 7。其典型流程包括特征点的检测（例如，使用SIFT、ORB、SURF等算法），随后对这些特征点进行描述，并最终在相邻帧之间进行特征点匹配 6。
一个理想的特征点应当具备一系列优良特性，以确保其在不同图像帧中的可靠性和实用性。这些特性包括：高辨识度，即能够与周围像素明显区分，具有极强的代表性；强可重复性，确保相同的特征点能够在后续图像中被再次检测到，从而进行有效匹配；高鲁棒性，意味着特征点应在光照变化、几何形变（如旋转、缩放、透视变形）、图像噪声或模糊等不利条件下保持稳定；以及高计算效率，即设计规则简单、占用内存少，有利于实时应用 6。然而，在实际工程中，计算效率与鲁棒性之间往往存在着相互矛盾的权衡，难以同时达到最优 6。
尽管特征点法在视觉SLAM领域取得了显著进展，但其固有局限性也日益凸显：
计算量大： 特征点的提取和描述过程，特别是对于SIFT这类复杂的描述子，通常计算量庞大且耗时较长 6。这在追求实时性的应用中构成了一个显著的瓶颈。
弱纹理场景失效： 在纹理单一或缺乏的场景中，例如白墙、空旷的走廊或光滑的桌面，传统特征点法难以提取出足够数量且具有高辨识度的可靠特征点。这导致VO的性能大幅下降，甚至完全失效 6。
动态环境敏感： 当场景中存在快速移动的物体时，这些物体的特征点在相邻帧之间的位置会发生突变，与相机自身的运动模式不符。这使得特征点匹配容易出错，从而降低VO在动态环境下的性能 6。
特征点丢失与匹配失败： 环境的剧烈变化、相机快速旋转或运动模糊等因素，都可能导致特征点在图像序列中丢失或匹配失败，进而影响位姿估计的连续性和准确性 11。
对特征点理想属性的追求，以及它们在实际应用中难以同时满足所有需求的困境，揭示了设计“完美”特征的内在难度。特征点法所面临的计算量大、弱纹理场景表现差、动态环境敏感等局限性，都直接源于其过度依赖离散且需精心设计的鲁棒特征。这种在特征提取和匹配环节出现的瓶颈，正是推动研究人员探索直接法等替代范式的主要原因，因为直接法试图绕过显式的特征计算过程。
在特征点设计中，鲁棒性与计算效率之间的权衡是一个核心问题。例如，高度鲁棒的特征（如SIFT）通常计算密集，而计算速度快的特征（如FAST）可能在鲁棒性方面有所欠缺 6。这种固有的权衡直接影响了特征点法VO系统的实时性能和最终的位姿估计准确性。正是这种对平衡点的不断探索，促使研究人员转向可能提供不同权衡点或完全避免这种困境的方法，例如直接法。

C. 直接法视觉里程计的诞生背景与核心思想

直接法视觉里程计（Direct Visual Odometry）的出现，正是为了克服传统特征点法VO所面临的部分缺点，特别是其在计算量和对纹理缺乏场景的适应性方面的不足 6。随着近年来一些直接法VO开源项目的涌现，这种方法正逐步进入视觉SLAM领域的主流视野 6。
直接法的核心思想与特征点法截然不同。它不依赖于显式的特征点提取、描述和匹配过程，而是直接利用图像的原始像素灰度信息来估计相机的运动。其根本理念是光度一致性（Photometric Consistency），即假设在理想情况下，三维空间中的同一个物理点，在不同相机视角下的图像投影，其像素亮度值应该保持相同。这意味着，如果能够准确地知道相机的运动，那么第一帧图像中某个点所对应的像素亮度，应该与其在第二帧图像中经过运动变换后对应点的像素亮度完全一致。
基于这一核心假设，直接法将相机运动估计问题转化为一个优化问题，其目标是最小化图像之间的光度误差（Photometric Error） 8。通过寻找一组相机位姿参数，使得当前帧图像中像素点与通过相机运动变换后在参考帧图像中对应像素点的亮度差异最小，从而实现相机位姿和场景结构的同步求解。
从“跟踪点特征几何位置的变化”到“直接利用像素灰度信息”的转变，代表了视觉里程计领域的一个根本性范式转变。这意味着研究的焦点从离散的、高层抽象的几何特征转向了连续的、低层原始像素数据。这种转变的潜在优势在于能够利用图像中更多的信息，尤其是在传统特征点稀疏或难以提取的区域。然而，这种方法也引入了新的敏感性，例如对光照变化、相机自动曝光调整或物体表面反射特性的敏感性。这是决定直接法优缺点的一个基础性假设。
直接法的核心在于最小化“光度误差” 8，这隐含着一个关键假设：三维空间中一个点的亮度在投影到不同图像帧时保持不变。虽然这一假设极大地简化了问题，使得直接对像素值进行优化成为可能，但在现实世界中，由于环境光照的动态变化、相机自动增益控制、物体表面反射特性或阴影等因素，这个假设往往难以完全满足 6。这些现实世界的偏差给直接法带来了关键的挑战，要求在追求最佳性能时，必须对这些因素进行鲁棒处理，或者限定其在特定、光照稳定的环境条件下运行。

D. 直接法与特征点法的对比概述

直接法与特征点法是视觉里程计领域的两种主要范式，它们在核心原理、数据利用、误差函数和计算流程上存在显著差异。
核心区别：
数据利用： 特征点法依赖于从图像中提取并描述的稀疏特征点进行处理；而直接法则直接利用图像的原始像素灰度信息，根据其利用像素信息的密度，可以分为稀疏、半稠密或稠密的像素点。
误差函数： 特征点法通常通过最小化“重投影误差”（一种几何误差）来估计相机运动；直接法则是通过最小化“光度误差”来求解位姿。
计算流程： 特征点法需要经历特征检测、特征描述、特征匹配等多个步骤；直接法跳过了这些耗时的步骤，直接在像素级别进行优化。
优劣势总结： 直接法最初的提出，正是为了克服特征点法在计算量大和不适用于纹理缺乏场景等方面的局限性 6。
这两种方法并非简单地孰优孰劣，而是具有互补的优势与劣势。特征点法由于其描述符的特性，在光照变化不剧烈的纹理丰富环境中通常表现出良好的鲁棒性。而直接法在纹理贫乏的区域表现突出，并且由于避免了特征计算的开销，理论上能够实现更快的处理速度。这种互补性暗示着，未来的研究方向可能会倾向于结合两者的优点，例如通过混合方法或自适应系统（如针对弱纹理区域的特征点优化算法 11），从而构建出更具鲁棒性的整体SLAM系统。
核心方法论（基于特征点或基于直接强度信息）的不同，也导致了两种方法在计算瓶颈上的差异。特征点法的主要计算负担集中在特征的检测和匹配阶段，特别是对于高分辨率图像或采用复杂描述符时。而直接法将计算负担转移到了密集或半密集的像素级优化上，尽管这部分计算可以通过并行化来加速，但其绝对处理量依然庞大。深入理解这些计算瓶颈，对于设计高效的SLAM硬件和软件架构至关重要。
以下表格总结了特征点法与直接法视觉里程计的主要对比：
表1：特征点法与直接法视觉里程计对比
维度
特征点法视觉里程计
直接法视觉里程计
核心思想
提取并匹配图像特征点，通过几何关系估计运动
直接利用图像像素灰度信息，最小化光度误差估计运动
优点
对光照变化、视角变化鲁棒性较好；发展成熟，算法库丰富
可在弱纹理区域工作；避免特征点提取与描述耗时，理论上更快；能利用图像所有像素信息
缺点
计算量大，特征点提取与描述耗时；在弱纹理区域性能下降或失效；易受动态物体影响
对光照变化、相机曝光非常敏感；容易陷入局部最小值；对图像模糊、噪声敏感
适用场景
纹理丰富、光照变化不剧烈、运动速度适中
纹理较弱、光照稳定、高速运动
对光照变化敏感度
较低（描述子设计）
高
对纹理需求
高
低（但需要梯度）
计算量特点
特征点提取与匹配是主要开销
像素级优化是主要开销
典型算法
ORB-SLAM（前端）
LSD-SLAM, DSO, SVO


II. 直接法的基本原理：光度一致性

直接法视觉里程计的核心在于其独特的光度一致性原理。本节将深入探讨这一原理，解释像素灰度与相机运动之间的几何联系，详细阐述光度误差的构建与优化目标，并讨论不同相机类型如何影响深度信息的获取与利用。

A. 像素灰度与相机运动的几何关系

在数字图像中，我们所看到的每一个像素，实际上都是三维空间中某个物理点在相机成像平面上的投影 1。这些图像通常以彩色RGB格式呈现，但为了简化处理，它们可以方便地转换为灰度图 6。灰度图中的每个像素值代表了对应空间点在成像平面上的亮度信息。
直接法的核心假设，即光度一致性假设，指出同一个三维空间点，在不同相机视角下的图像投影，其像素亮度值应该保持不变。这意味着，如果已知相机的运动参数（旋转和位移），那么一个点在第一帧图像中的像素亮度，应该与其在第二帧图像中经过相机运动变换后，在对应位置上的像素亮度相同。这个假设是直接法能够直接利用像素信息进行位姿估计的基石。
相机模型将三维世界投影到二维图像中 5。从二维图像中恢复三维信息，本质上是一个病态的逆问题，即存在多个三维场景可以投影出相同的二维图像。直接法通过假设一个三维点的强度与其在不同图像帧上的二维投影之间存在直接且恒定的关系，从而简化了这一逆问题。这个假设使得算法能够直接对像素值进行优化，避免了复杂的特征提取和匹配过程。然而，这种简化也意味着直接法对任何与理想情况（例如，光照变化、相机增益的自动调整、物体表面反射特性的变化）的现实世界偏差都高度敏感。这种敏感性是直接法在实际应用中面临挑战，并对其优缺点产生决定性影响的基础假设。

B. 光度误差的定义与构建

基于光度一致性假设，直接法通过构建光度误差函数来量化不同图像帧之间像素亮度的不一致性。光度误差通常定义为当前帧图像中某个像素点与通过相机运动变换后，在参考帧图像中对应像素点的亮度差异。
在数学形式上，对于图像中的任意一个像素点，其光度误差 e 可以表示为：

e=I2​(p2​)−I1​(p1​)

其中，I1​ 和 I2​ 分别代表第一帧（参考帧）和第二帧（当前帧）图像的像素亮度值。p1​ 是参考帧中的像素坐标，而 p2​ 则是 p1​ 对应的三维空间点经过相机运动变换（旋转 R 和平移 t）和深度信息 d 投影到第二帧后的像素坐标。具体来说，p2​ 是 p1​ 及其深度 d 经过相机位姿 T（由 R 和 t 构成）变换后的投影结果，即 p2​(p1​,T,d)。
与依赖离散特征匹配（如暴力匹配 13 或其他匹配器 6）的特征点法不同，直接法将位姿估计问题表述为对像素强度进行连续优化。这种方法允许实现亚像素级别的精度，并能够潜在地利用图像中更密集的像素信息。光度误差的定义直接将寻找相机运动的问题转化为一个数学上的最小化问题，随后通过迭代的数值方法进行求解。

C. 优化目标：最小化光度误差

直接法的核心优化目标是找到一组相机运动参数（通常以李代数形式表示的旋转和平移），使得所有选定像素点的光度误差的平方和最小化。这是一个典型的非线性最小二乘问题。
其目标函数可以表示为：

Tmin​i∈pixels∑​∣∣I2​(p2​(p1​,T,d))−I1​(p1​)∣∣2

在这个目标函数中，T 代表相机从第一帧到第二帧的位姿变换（包括旋转 R 和平移 t）。求和符号表示对所有参与优化的像素点进行累加。通过最小化这个函数，算法旨在找到最能解释两帧图像之间像素亮度差异的相机运动。
最小化光度误差通常是一个非线性、非凸的优化问题。这意味着在求解过程中，迭代优化算法（如高斯-牛顿法或列文伯格-马夸尔特法 11）可能会陷入局部最小值，从而导致位姿估计不准确。这种固有的挑战要求在实际应用中采取一系列策略，例如提供良好的相机位姿初始猜测、使用鲁棒的损失函数（如Huber核函数 7）来抑制离群点的影响，以及可能采用多尺度方法（如图像金字塔 12）来改善收敛性并避免不良解决方案。

D. 深度信息的利用：单目、双目与RGB-D相机

在视觉里程计中，深度信息的获取是实现三维位姿估计和地图构建的关键。不同类型的相机在获取深度信息方面具有不同的机制和挑战。
单目相机：
深度估计： 单目相机通过自身的移动来估计深度，这种深度估计是动态的，即需要相机在不同位置拍摄多张图像才能推断出深度信息 5。
尺度不确定性： 单目相机作为唯一的传感器时，无法确定场景的绝对尺度信息 5。这意味着通过单目视觉估计出的轨迹和地图，其大小是相对于真实世界有一个未知的尺度因子。因此，估计结果只能在未知尺度因子下恢复 14。如果尺度仅在初始化过程中确定，那么在后续的连续测量中，很可能会发生尺度漂移，导致轨迹的累积误差不断放大 5。
初始化： 单目视觉里程计在进行PnP（Perspective-n-Point）位姿估计前，通常必须进行初始化 6。初始化过程通常需要相机有足够的平移运动（而非纯旋转），以便通过三角测量等方法来三角化出初始的三维点，从而解决尺度不确定性问题 6。
双目/RGB-D相机：
直接深度获取： RGB-D相机（如Kinect）是一种新型相机，它利用红外结构光或飞行时间（ToF）原理，能够直接测量图像中每个像素到相机的距离，从而提供丰富的深度信息 1。双目相机则通过左右两幅图像的视差来计算深度信息，且可以在静止状态下完成深度获取 5。
PnP应用： 由于双目或RGB-D相机能够直接获取特征点的三维位置，因此在基于这些相机的视觉里程计中，可以直接使用PnP算法来估计相机运动，而无需依赖对极约束来求解位姿 6。PnP方法是姿态估计中非常重要的一种，它在仅有少量匹配点的情况下也能获得较好的运动估计 6。
三角测量（Triangulation）：
三维点恢复： 三角测量是根据从两个或多个不同视角拍摄的二维图像点来恢复其对应的三维空间位置的几何原理 1。在单目视觉里程计中，当相机在不同位置拍摄图像后，可以通过三角测量来获得图像点对应的三维位置 6。
步骤： 三角测量的基本步骤通常包括：首先进行像素点的匹配，然后（对于单目情况）确定极线，最后根据对极约束和几何关系计算出匹配像素点的深度值 16。
相机类型的选择（单目、双目、RGB-D）从根本上影响了视觉里程计算法的设计和其复杂性。单目系统面临固有的尺度不确定性问题 5，需要经过仔细的初始化过程 6，并可能导致随时间累积的尺度漂移 5。相比之下，立体相机和RGB-D相机能够提供直接的深度信息，从而简化了三维点的恢复过程 1，并可以直接基于PnP算法进行位姿估计 6，而无需依赖对极几何进行运动估计。这突出了硬件能力如何直接影响算法的选择和最终系统的鲁棒性。
尽管直接法主要操作于像素强度信息，但它们在地图构建时，以及有时在初始化或使用PnP算法时，仍然需要三维点信息 6。三角测量 1 是将来自多个视点的二维观测转换为三维坐标的几何过程。这意味着，虽然直接法避免了显式的特征匹配来估计位姿，但它们通常仍然依赖几何原理进行地图构建或初始深度估计。三角测量的准确性直接影响着最终三维地图的质量和位姿估计的精度。

III. 直接法的数学推导与求解

直接法视觉里程计的运动估计本质上是一个非线性优化问题。本节将深入探讨这一问题的数学基础，包括其构建方式、雅可比矩阵的计算、迭代求解方法，以及如何通过鲁棒性处理应对数据中的噪声和异常值。

A. 运动估计的非线性优化问题

在直接法中，相机运动估计被建模为一个典型的非线性优化问题 6。其核心目标是找到一组最优的相机位姿参数（通常以李代数的形式表示旋转和平移），使得光度误差函数达到最小化。
在视觉SLAM的整体框架中，前端（即视觉里程计）负责提供待优化的数据以及这些数据的初始值，而后端优化模块则负责整个系统的全局优化过程 1。在视觉SLAM领域，后端优化主要涉及滤波和非线性优化算法 1。
光束法平差（Bundle Adjustment, BA）是计算机视觉中一种经典的非线性优化方法，它通过同时调整相机位姿和三维点坐标来最小化重投影误差 6。尽管BA通常与特征点法中的重投影误差紧密相关，但其非线性优化的思想和技术同样适用于直接法，用于最小化光度误差。
非线性优化和光束法平差（BA） 6 在各种视觉里程计背景下（包括特征点法和直接法）的持续应用，表明它们是SLAM领域的核心数学工具。这意味着，深入理解非线性最小二乘问题、雅可比矩阵的计算以及迭代求解器的工作原理，对于任何SLAM实践者而言都是基础且不可或缺的知识。传感器噪声问题 1 正是优化算法旨在缓解的核心挑战，通过在给定噪声测量的情况下，寻找最能解释观测数据的相机状态和环境结构。

B. 雅可比矩阵的计算：链式法则与像素梯度

对于任何非线性优化问题，为了使用如高斯-牛顿法或列文伯格-马夸尔特法等迭代求解器，我们都需要计算误差函数对优化变量（即相机位姿参数）的导数，这个导数矩阵就是雅可比矩阵。它是迭代优化算法能够有效收敛的核心。
在直接法中，光度误差 e=I2​(p2​(T))−I1​(p1​) 对相机位姿 T 的导数需要通过链式法则进行计算。具体来说，其导数可以表示为：

∂T∂e​=∂p2​∂I2​​∂T∂p2​​
∂p2​∂I2​​： 这一项表示图像 I2​ 在像素点 p2​ 处的梯度。它量化了像素亮度值随像素坐标变化的速率。图像梯度是直接法能够工作的关键，因为它指明了在图像平面上哪个方向的亮度变化最剧烈。
∂T∂p2​​： 这一项表示像素坐标 p2​ 随相机位姿 T 变化的速率。它的计算涉及到相机的内参、外参以及三维点的深度信息。通过这个导数，我们可以知道相机位姿的微小变化如何影响三维点在图像上的投影位置。
直接法的雅可比矩阵计算高度依赖于图像梯度，即像素强度随位置的变化。这意味着图像中具有强梯度（例如边缘、角点，即使它们不是传统意义上的“特征点”）的区域，对光度误差的贡献更大，因此在优化过程中提供了更多的信息。相反，那些纹理平坦、强度均匀的区域将具有接近零的梯度，为位姿估计提供的信息非常少。这是直接法在极端弱纹理场景下仍然存在的一个微妙限制。这种对梯度的依赖性，与特征点法中对“丰富纹理”的需求 6 存在内在联系，表明尽管直接法在“弱”纹理下表现更好，但它们仍然需要“一些”纹理（即梯度信息）才能有效工作。

C. 迭代求解方法：高斯-牛顿法与列文伯格-马夸尔特法

非线性最小二乘问题的求解通常采用迭代方法，其中高斯-牛顿法和列文伯格-马夸尔特法是两种广泛应用且效果显著的算法。
高斯-牛顿法（Gauss-Newton Method）： 这是一种常用的非线性最小二乘问题求解方法。其基本思想是将非线性误差函数在当前估计点处进行局部线性化，然后通过迭代求解一个线性方程组来逼近最优解。高斯-牛顿法在初始值接近最优解时，收敛速度通常较快。
列文伯格-马夸尔特法（Levenberg-Marquardt, LM）： LM法是高斯-牛顿法的一种改进，它巧妙地结合了高斯-牛顿法和梯度下降法的优点。当初始值距离最优解较远时，LM法表现得更像梯度下降法，具有更好的全局收敛性，能够更稳定地找到解；而当迭代过程接近最优解时，它又表现得更像高斯-牛顿法，收敛速度更快 11。由于其良好的收敛性和鲁棒性，LM法在许多非线性优化问题中被广泛采用，包括视觉里程计中的位姿估计 11。
高斯-牛顿法和列文伯格-马夸尔特法是解决非线性最小二乘问题的标准算法。高斯-牛顿法在接近最优解时收敛速度快，但如果初始猜测不够准确，可能会导致算法发散。列文伯格-马夸尔特法 11 提供了一种更鲁棒的阻尼方法，它能够根据当前迭代步的质量，自适应地在高斯-牛顿法和梯度下降法之间进行切换。这种算法选择体现了在收敛速度和收敛可能性之间进行权衡的工程考量，这对于初始位姿猜测不总是完美的实时系统尤为重要。这种选择直接影响着视觉里程计系统的稳定性和可靠性。

D. 鲁棒性处理：离群点剔除与Huber核函数

在实际的视觉里程计系统中，图像数据往往受到多种因素的影响，如光照变化、视角变化、运动模糊、相机噪声等，导致相邻图像帧之间可能存在较大差异 6。这些因素会引入错误的数据关联，产生不符合模型假设的测量值，我们称之为“离群点”（outliers） 6。为了获得准确可靠的相机运动估计，移除或减小这些离群点的影响至关重要 6。
为了应对离群点问题，计算机视觉领域发展出了多种鲁棒估计方法：
RANSAC (Random Sample Consensus)： 随机采样一致性算法是一种迭代方法，通过随机选择最小样本集来估计模型参数，并从中识别出符合模型的内点（inliers）和不符合模型的离群点 17。RANSAC被广泛应用于计算基础矩阵等几何模型 17。
LMedS (Least Median of Squares)： 最小中值平方是一种比RANSAC更具鲁棒性的估计方法。其目标是最小化残差的中值，而不是残差的平方和，因此对离群点不那么敏感 17。
MSAC (M-estimator SAmple Consensus)： M估计器采样一致性是RANSAC的一种变体，它通过设置一个距离阈值来确定内点，通常比标准RANSAC算法收敛更快 17。
除了上述离群点剔除算法，在非线性优化中，还可以引入**鲁棒核函数（Robust Kernel Function）**来减小离群点对优化过程的影响。例如，Huber核函数 7 是一种常用的鲁棒核函数。它的特点是在误差较小时（即内点），采用平方误差（L2范数）进行惩罚，保持优化效率；而在误差较大时（即离群点），则采用线性误差（L1范数）进行惩罚。这种设计有效地抑制了大的误差（离群点）对总损失函数的贡献，使得优化过程更加稳定，避免了少数离群点主导整个优化结果的情况 7。
数据中存在“噪声和离群点” 18 是计算机视觉中普遍存在的问题，不仅影响特征点法（如不匹配 7），也影响直接法（如光度一致性假设的违反）。鲁棒损失函数（如Huber核函数 7）和离群点剔除技术（如RANSAC/MSAC/LMedS 17）并非仅仅是可选的增强功能，而是构建实用SLAM系统所
必不可少的组成部分。它们确保了少数错误的测量不会破坏整个位姿估计的准确性。这突出了在真实世界、嘈杂环境中部署SLAM时所面临的实际挑战。
尽管RANSAC/LMedS/MSAC等算法在研究资料中明确提及用于基础矩阵估计 17（这通常是基于特征点的方法），但“离群点剔除” 6 和使用鲁棒核函数（如Huber 7）的概念，在SLAM中的任何优化问题中都具有广泛的适用性。这表明鲁棒统计的原理是可迁移的，并且对于构建可靠的视觉里程计系统至关重要，无论它们是基于特征点的方法还是直接法。

IV. 直接法的分类与典型算法解析

直接法视觉里程计根据其利用图像像素信息的密度，可以细分为稀疏、半稠密和稠密三种类型。每种类型都有其独特的特点、优缺点以及典型的算法实现。

A. 稀疏直接法 (Sparse Direct Methods)

稀疏直接法的核心思想是仅利用图像中具有大梯度的稀疏像素点进行优化。这些点通常位于图像中亮度变化最剧烈的区域，因此包含了最丰富的信息，在某种程度上类似于特征点。然而，与特征点法不同的是，稀疏直接法不进行显式的特征描述和匹配，而是直接对这些选定像素点的光度误差进行优化。
特点：
优点： 由于只处理少量像素点，其计算量相对较小，处理速度快，非常适合实时应用。此外，它在弱纹理区域仍能工作，因为只要有足够的梯度信息即可，不像特征点法那样需要可辨识的“角点”或“斑块”。
缺点： 它的性能高度依赖于图像梯度，因此对光照变化较为敏感。由于只利用稀疏的像素信息，其生成的地图也是稀疏的，缺乏场景的细节信息。
典型算法： DSO (Direct Sparse Odometry) 是稀疏直接法的一个代表性算法。它通过最小化光度误差来同时优化相机位姿和稀疏的三维点结构。DSO将三维几何表示为稀疏的大梯度点，并使用滑动窗口优化技术，以实现位姿和结构的同步估计 8。
稀疏直接法（如DSO 8）代表了在信息密度和计算成本之间的一种折衷。它们不像稠密方法那样使用所有像素，但比仅仅依赖“特征点”（如特征点法）使用更多的像素信息。通过专注于那些具有强梯度的像素，稀疏直接法旨在获取最具信息量的数据点进行优化，同时保持计算负载在可管理的范围内，以实现实时性能。这种策略直接回应了稠密方法的计算复杂性以及特征点法在无纹理区域的局限性。

B. 半稠密直接法 (Semi-Dense Direct Methods)

半稠密直接法的核心思想是利用图像中所有具有明显梯度的像素点（如边缘）进行优化，而忽略那些亮度变化平缓的区域。它介于稀疏和稠密之间，只处理那些提供足够信息（即有足够梯度）的像素，从而在地图密度和计算效率之间取得平衡。
特点：
优点： 相比稀疏法，半稠密法能够提供更稠密的地图，包含更多的场景结构细节。同时，它比稠密法计算量小，更容易实现实时性。在弱纹理区域，其表现通常优于传统的特征点法。
缺点： 与所有直接法一样，它仍然对光照变化敏感。虽然地图密度有所提高，但仍不如稠密法那样完整。
典型算法： LSD-SLAM (Large-Scale Direct SLAM) 是半稠密直接法的一个著名实现。它通过最小化光度误差来估计相机运动，并将三维几何表示为半稠密的深度图 8。LSD-SLAM不仅优化位姿和结构，还包含了回环检测、重定位和最终优化等模块，是一个较为完整的SLAM系统 8。
半稠密方法（如LSD-SLAM 8）旨在提供比稀疏方法更丰富的环境表示，同时避免稠密方法的高昂计算成本。通过关注那些具有显著强度变化的像素（例如，图像中的边缘），它们能够捕获更多的结构信息，同时仍然保持计算上的可行性。这代表了直接法的一个重要演进步骤，旨在通过利用更多的像素数据来提高地图质量和系统的鲁棒性。

C. 稠密直接法 (Dense Direct Methods)

稠密直接法的核心思想是利用图像中的所有像素点进行优化，旨在构建一个完整的、高密度的三维地图。
特点：
优点： 理论上利用了图像中的所有可用信息，能够提供最详细、最完整的场景三维地图信息。
缺点： 由于需要处理图像中的每一个像素，其计算量极其巨大，实时性非常差，通常需要强大的GPU加速才能勉强达到可接受的帧率。此外，它对光照变化和噪声非常敏感，因为即使是每个像素的微小亮度变化，都可能对最终的优化结果产生显著影响。
典型算法： 例如，DTAM (Dense Tracking and Mapping) 是稠密直接法的一个早期代表。
稠密直接法通过使用图像中的所有像素，理论上能够从图像中提取最大量的信息用于位姿和结构估计。这可以导致生成高度详细和完整的3D重建结果。然而，其计算成本极高，使得在没有专用硬件（如高性能GPU）的情况下实现实时性能变得极具挑战性。这突出了SLAM领域中一个基本而普遍的权衡：对全面环境理解的渴望与实时操作的实际限制之间的平衡。

D. 典型算法案例：LSD-SLAM, DSO, SVO

除了上述分类，一些典型的直接法算法在实际应用中展现了不同的性能和特点：
LSD-SLAM： 如前所述，LSD-SLAM是一种半稠密直接法，其设计目标之一就是实现实时性能，通常可以达到每秒30帧（30Hz）的运行速度 8。
DSO： DSO是一种稀疏直接法，同样注重实时性，其运行速度也能达到30Hz 8。
SVO (Semi-direct Visual Odometry)： SVO是一种混合方法，巧妙地结合了直接法和特征点法的优点。它利用直接法（基于边缘点和角点）来估计相机在相邻帧之间的快速运动，同时采用特征点法（通过最小化重投影误差）进行帧到关键帧的位姿精化 8。SVO的设计目标是实现极高的运行速度，能够达到每秒100到400帧（100-400 fps），使其适用于高速运动场景 8。
ESVO2： 这是一种基于事件相机的双目视觉与惯性里程计系统，专注于优化三维建图效率和位姿估计精度。事件相机作为新一代传感器，相比传统相机具有更高的时间分辨率和动态范围，这为在高速运动或高动态范围光照场景下的位姿估计提供了强有力的支持 19。
对“实时性能”（LSD-SLAM和DSO通常为30Hz；SVO可达100-400 fps）的明确强调 8，凸显了视觉SLAM在实际应用中对效率的必要性。SVO所采用的混合方法（直接法用于帧间运动，特征点法用于关键帧精化） 8 是一种结合两种范式优点的复杂解决方案，这表明在实际工程中，“最佳”算法通常是多种技术的集成。ESVO2利用事件相机 19 的例子，则指向了未来传感器技术的发展方向，旨在克服传统相机在极端条件下的局限性，进一步强调了该领域为实现更好性能而不断进行的创新。
以下表格总结了直接法视觉里程计的分类及其特点：
表2：直接法视觉里程计分类与特点
类型
核心思想
优点
缺点
典型算法
稀疏直接法
仅利用图像中具有大梯度的稀疏像素点进行优化
计算量相对较小，速度快，适合实时应用；在弱纹理区域仍能工作
依赖于图像梯度，对光照变化敏感；地图稀疏，细节不足
DSO (Direct Sparse Odometry)
半稠密直接法
利用图像中所有具有明显梯度的像素点（如边缘）进行优化
比稀疏法提供更稠密的地图；比稠密法计算量小；在弱纹理区域表现优于特征点法
仍对光照变化敏感；地图密度介于稀疏和稠密之间
LSD-SLAM (Large-Scale Direct SLAM)
稠密直接法
利用图像中所有像素点进行优化，旨在构建一个完整的稠密地图
提供最详细的地图信息；理论上利用了所有图像信息
计算量巨大，实时性差，通常需要GPU加速；对光照变化、噪声非常敏感
DTAM (Dense Tracking and Mapping)


V. 直接法的优缺点与实际应用考量

直接法视觉里程计作为视觉SLAM前端的重要组成部分，在特定场景下展现出显著优势，但也面临着一系列挑战和局限性。全面理解这些方面对于选择和部署合适的SLAM系统至关重要。

A. 优势：在弱纹理、高速运动场景下的表现

直接法视觉里程计相较于传统的特征点法，在某些特定场景下具有明显的优势：
弱纹理场景适应性： 直接法通过直接利用图像的像素灰度信息进行优化，而不是依赖于可辨识的、经过提取和描述的特征点。因此，在纹理单一或缺乏的场景中，例如白墙、空旷的走廊或光滑的平面，直接法能够比特征点法更好地工作，因为这些场景往往难以提供足够数量的可靠特征点 6。
高速运动与高动态范围光照： 直接法避免了特征点提取和匹配的复杂且耗时的过程，这使得它对图像模糊具有更高的容忍度。对于高速运动的相机或在高动态范围光照场景下的位姿估计，直接法（特别是结合事件相机等新型传感器，如ESVO2系统 19）能够提供强有力的支持，因为事件相机本身就具有高时间分辨率和高动态范围的特点 19。
信息利用率高： 从理论上讲，直接法利用了图像中的所有像素信息（对于稠密直接法而言），从而能够获得更完整、更稠密的场景三维结构信息。即使是稀疏或半稠密直接法，也比特征点法利用了更多像素的梯度信息。
直接法的这些优势直接解决了特征点法所面临的一些核心弱点 6。这使得直接法特别适用于那些传统特征检测器难以有效工作的挑战性环境，例如缺乏纹理的室内空间、快速移动导致的图像模糊，或者光照剧烈变化的场景。这意味着在某些特定的应用场景中，直接法可能成为唯一可行的视觉里程计解决方案，尽管它自身也伴随着一系列需要解决的挑战。

B. 挑战与局限性

尽管直接法具有显著优势，但在实际应用中也面临诸多挑战和局限性。

1. 光照变化与曝光问题

问题表现： 直接法严重依赖光度一致性假设，即认为同一三维点在不同图像帧中的像素亮度应保持不变。因此，它对环境光照的动态变化（如光线忽明忽暗、阴影的移动或突然出现）以及相机自身曝光参数的自动调整非常敏感 6。当图像过暗、噪点过多，或过亮、过度曝光时，图像的像素值会失真，严重破坏光度一致性假设，导致光度误差无法准确反映相机运动，进而引发位姿估计的漂移甚至失败 6。
应对策略： 研究者们提出了多种应对方法，例如通过光照非线性调整 12 等图像预处理技术来增强图像细节和鲁棒性，或者在优化过程中引入鲁棒核函数（如Huber核函数 7）来减小大误差（由光照变化引起）的影响。此外，进行光度标定或结合对光照不敏感的传感器也是可能的方向。
光度一致性假设（即像素亮度保持不变）与现实世界中普遍存在的光照变化 6 之间存在根本性的冲突。这是直接法的一个深层限制。尽管研究人员不断探索各种解决方案（例如，光度校准、鲁棒损失函数），但在动态光照条件下，这仍然是直接法实现鲁棒性的一个重大障碍。这也解释了为什么依赖更抽象描述符的特征点法通常对光照变化表现出更强的鲁棒性。

2. 初始化与尺度不确定性

问题表现： 单目直接法与单目特征点法一样，存在固有的尺度不确定性问题 5。由于相机将三维世界投影为二维图像，导致在深度方向上缺乏直接观测，一个远处的巨大物体在图像中可能与一个近处的小物体投影出相同的大小 5。因此，单目系统只能恢复出尺度未知的相机轨迹和环境地图 14，并且在长时间运行中，累积误差可能导致尺度漂移，无法进行绝对定位和导航 5。
应对策略：
初始化： 单目视觉里程计在开始进行PnP位姿估计之前，必须先进行初始化 6。初始化通常需要相机进行足够的平移运动（而非纯旋转），以便能够通过三角测量等方法三角化出初始的三维点，从而确定场景的初始尺度 6。
多传感器融合： 解决尺度不确定性最有效的方法之一是引入其他传感器进行融合，例如惯性测量单元（IMU）5。IMU能够提供独立的运动信息，包括加速度和角速度，从而为系统提供绝对尺度信息。例如，ESVO2系统通过引入IMU测量数据作为运动先验，构建了紧凑且稳健的后端优化框架，实现了IMU偏置与线速度的实时估计，从而有效解决了尺度问题 19。
立体/RGB-D相机： 使用双目相机或RGB-D相机可以从根本上解决尺度问题，因为它们能够直接获取场景的深度信息，无需依赖相机运动来估计 1。
单目视觉里程计中的尺度不确定性 5 并非仅仅是技术故障，而是源于透视投影的一个基本几何约束。一个远处的大物体在图像中可能与一个近处的小物体投影出相同的大小 5。这意味着，在没有外部信息（例如，已知物体尺寸、IMU集成或初始多视图设置）的情况下，单目系统无法固有地确定绝对深度或尺度。这个问题需要特定的初始化程序（例如，足够的平移 6）或传感器融合（例如，与IMU结合 5）来提供度量尺度。

3. 计算效率与实时性

问题表现： 尽管直接法旨在克服特征点法的部分计算量问题 6，但对于稠密直接法而言，由于需要处理图像中的所有像素，其计算量依然巨大，难以在普通的CPU上实现实时性 5。即使是稀疏和半稠密直接法，虽然在效率上有所改善，但要达到高帧率的实时性能，仍需要精心的优化。
应对策略： 采用稀疏或半稠密方法 8 以减少处理的像素数量；利用图像金字塔进行降采样，在不同尺度上进行优化，从而提高计算效率 12；充分利用GPU进行并行计算，以加速像素级的光度误差计算和优化过程；以及使用高效的优化库（如Ceres Solver, g2o 7）。
对“实时性” 8 和“低计算负载” 5 的强调，凸显了视觉SLAM不仅是一个学术研究问题，更是一个实际的工程挑战。稀疏、半稠密和稠密直接法之间的选择 8 直接反映了在地图精度/完整性与计算可行性之间进行平衡的尝试。这也意味着，计算硬件（例如，GPU、专用AI芯片）和高效软件实现的进步与算法创新同样重要，它们共同推动着SLAM性能的边界。

4. 动态环境的影响

问题表现： 在存在运动物体的动态场景中，直接法同样会受到影响 6。运动物体的像素点不符合相机自身的运动模型，导致光度一致性假设被破坏，从而使光度误差计算不准确，进而影响相机位姿估计的精度和鲁棒性。地图中可能出现“鬼影”或不一致的结构。
应对策略： 针对动态环境，研究者们提出了多运动视觉里程计（Multi-motion Visual Odometry, MVO）的概念，专门用于在动态场景中估计动态物体的位姿变化，从而区分背景和前景运动 4。此外，一些方法通过计算图像灰度概率分布来剔除无纹理区域，这也可以间接帮助处理动态区域，因为动态区域通常纹理变化剧烈或不符合静态场景假设 12。引入语义信息来识别和分割动态物体也是一个重要的研究方向。
大多数传统的视觉里程计和SLAM算法都隐含地假设环境是静态的。移动物体（例如，行走的人 6）违反了这一基本假设，导致错误的特征匹配或光度不一致，进而引发位姿估计错误。这是在以人为中心或交通繁忙的环境中部署SLAM所面临的主要挑战。解决方案通常涉及对动态物体进行分割，或使用更复杂的运动模型（例如，多运动VO 4）。这推动了该领域向更智能、更鲁棒的场景理解发展，而不仅仅是简单的自我运动估计。

5. 局部最小值

问题表现： 直接法中的相机位姿估计是一个非线性优化问题，其目标函数通常是非凸的。这意味着在迭代优化过程中，算法可能收敛到错误的局部最优解，而不是全局最优解。一旦陷入局部最小值，位姿估计就会不准确，导致系统无法正常工作或产生较大的漂移。
应对策略： 采用良好的初始值估计，例如从上一帧的位姿或通过惯性测量单元（IMU）提供先验信息；使用多尺度优化，即在图像金字塔的不同层级上进行优化，从粗到细地逼近最优解；以及结合随机采样一致性算法（RANSAC/MSAC/LMedS 17）进行外点剔除，以减少异常数据对优化过程的干扰，从而提高收敛到全局最优解的概率。

C. 适用场景与系统集成

直接法视觉里程计在特定场景下具有独特的优势，并通过与其他技术集成来进一步提升鲁棒性。
适用场景： 直接法在弱纹理、光照稳定以及相机高速运动的场景下具有显著优势 6。例如，在室内走廊、隧道等纹理稀疏的环境中，或在无人机、高速机器人等快速移动平台上的应用。
多传感器融合： 为了提高系统的整体鲁棒性和精度，直接法经常与其他传感器进行融合，其中最常见的是与惯性测量单元（IMU）的融合 19。IMU能够提供独立的运动信息，弥补视觉里程计在纯旋转、弱纹理或光照剧烈变化时的不足，并解决单目视觉的尺度不确定性问题 5。
多特征融合： 在一些弱纹理场景中，仅依靠点特征可能不够丰富。研究表明，融合点特征和线特征可以提高特征检测和跟踪的鲁棒性及精度 7。这种混合方法可以利用不同类型特征的互补优势。
将直接法与IMU 19 或线特征 7 相结合的实践，表明了SLAM领域的一个更广泛趋势：没有单一的传感器或算法是完美的。鲁棒的SLAM系统通常会融合来自多个传感器（例如，相机、IMU、激光雷达 1）的数据，并且/或者结合不同的算法范式（例如，点特征与线特征 7；直接法与特征点法，如SVO 8）。这种多模态、混合方法是克服每种技术各自局限性，并实现在各种真实世界条件下更高精度和鲁棒性的关键策略。
以下表格总结了直接法视觉里程计常见的挑战及其应对策略：
表3：直接法视觉里程计常见挑战与应对策略

挑战
具体表现
影响
应对策略
光照变化/曝光
图像过亮/过暗，像素值失真，光度一致性假设被破坏
光度误差无法准确反映运动，导致位姿估计漂移或失败
图像预处理（如亮度非线性调整 12），鲁棒核函数（Huber 7），光度标定，或结合对光照不敏感的传感器
尺度不确定性 (单目)
单目相机无法确定绝对深度，轨迹和地图只能在未知尺度下恢复
累积误差导致尺度漂移，无法进行绝对定位和导航
初始化时通过特定运动（非纯旋转 6）或已知结构确定尺度；融合其他传感器（如IMU 5）；使用双目/RGB-D相机 1
计算效率
像素级优化计算量大，难以满足实时性要求
限制了在高速移动平台上的应用，增加了硬件成本
稀疏/半稠密方法 8；多尺度图像金字塔 12；GPU并行计算；高效的优化库（如Ceres, g2o 7）
动态环境
场景中存在运动物体，其像素点不符合相机运动模型
错误的像素对应导致位姿估计不准确，地图中出现“鬼影”
动态物体分割与剔除 6；多运动视觉里程计（MVO 4）；引入语义信息
局部最小值
非线性优化过程中，算法可能收敛到错误的局部最优解
导致位姿估计不准确，系统无法正常工作
良好的初始值估计；多尺度优化；随机采样一致性算法（RANSAC/MSAC/LMedS 17）进行外点剔除


VI. 学习建议与未来展望

对于初学者而言，掌握直接法视觉里程计的理论与实践是深入理解视觉SLAM的关键一步。本节将提供实用的学习建议、常见的调试技巧，并展望直接法在未来SLAM领域的发展方向。

A. 初学者学习路径与实践建议

学习直接法视觉里程计，理论知识与动手实践的结合至关重要。
理论与实践结合： 强烈建议初学者下载并运行《视觉SLAM十四讲》提供的代码 21。通过亲手编译、运行并修改代码，可以更直观地理解算法的内部机制和参数对结果的影响，从而加深对理论知识的理解。
环境要求理解： 深入理解影响视觉里程计效果的环境因素至关重要。这些因素包括合适的光照强度（避免过暗或过亮）、场景中具有相对丰富的纹理、相机捕捉的图像序列应连续且相邻帧之间有足够的重叠区域，以及最好在静态场景下运行 6。理解这些条件有助于在实际应用中评估直接法的适用性。
优秀特征点理解： 即使直接法不显式提取特征点，但理解“优秀特征点”所应具备的特性（如高辨识度、强可重复性、高鲁棒性和高计算效率） 6，对于理解图像信息质量如何影响视觉里程计的性能仍然具有指导意义。这有助于判断哪些图像区域对位姿估计贡献更大，哪些区域可能导致问题。
“下载并运行代码” 21 以及“良好VO结果”的详细条件 6 等建议，强调了SLAM是一个高度经验性的领域。理论理解必须辅以实践经验。初学者不仅需要理解算法的
工作原理，还需要理解它们在何种条件下表现良好，以及如何处理真实世界数据中的缺陷和不确定性。这突出了理想化理论模型与实际系统部署之间存在的差距，并指导学习者如何弥合这一差距。

B. 常见问题与调试技巧

在实践直接法视觉里程计时，初学者可能会遇到一些常见问题。了解这些问题并掌握相应的调试技巧，对于构建鲁棒的SLAM系统至关重要。
尺度漂移： 这是单目视觉里程计的固有问题，尤其是在相机进行纯旋转运动或缺乏足够的平移时，尺度信息无法确定，导致轨迹随时间漂移 5。调试时，应检查相机运动是否包含足够的平移。缓解方案包括融合IMU数据以引入绝对尺度 5，或直接采用双目/RGB-D相机。
光照变化： 直接法对光照敏感，剧烈的光照变化可能导致光度误差计算不准确，进而使位姿估计失败。调试时，应检查图像预处理步骤是否有效处理了亮度变化，并确保鲁棒核函数（如Huber核函数）已正确应用 7。在受控光照环境下进行测试，逐步引入光照变化，有助于定位问题。
局部最小值： 由于直接法的优化问题通常是非凸的，算法可能陷入局部最优解。调试时，需检查初始位姿估计是否合理，并尝试多尺度优化策略，从图像金字塔的粗层开始优化，逐步精化到细层，以增加收敛到全局最优解的概率。
动态物体： 场景中的运动物体会违反光度一致性假设，导致错误的位姿估计 6。调试时，可以首先在纯静态环境下运行系统，确保其性能稳定。随后，逐步引入动态元素，观察系统表现，并考虑采用动态物体分割或多运动视觉里程计（MVO）等方法来处理。
“常见问题” 5 的提及意味着调试和故障排除是SLAM开发中不可或缺的一部分。尺度漂移或精度差等问题不仅仅是理论概念，更是实际工程中必须克服的障碍。理解这些问题的根本原因（例如，单目纯旋转导致的尺度不确定性 6；动态物体违反静态场景假设 6）是有效诊断和解决问题的关键。本节旨在指导初学者如何系统地诊断和解决这些常见故障，从而提升其解决实际问题的能力。

C. 直接法视觉里程计的最新研究进展

直接法视觉里程计领域仍在不断发展，新的研究方向和技术不断涌现，旨在克服其现有局限性并提升性能。
多运动视觉里程计（MVO）： 传统的视觉里程计通常假设场景是静态的。为了应对动态环境的挑战，多运动视觉里程计（MVO）被提出，专门用于在动态场景中估计动态物体的位姿变化，从而更准确地分离相机自身的运动与场景中其他物体的运动 4。这是解决传统VO在动态环境下性能下降问题的重要方向。
事件相机（Event Cameras）的应用： 事件相机是一种新型的仿生视觉传感器，它不像传统相机那样以固定帧率捕获图像，而是仅在像素亮度发生变化时才记录“事件”。这种特性使得事件相机具有更高的时间分辨率和动态范围 19。结合事件相机的直接法（例如ESVO2系统 19），能够为高速运动或高动态范围光照场景下的位姿估计提供强有力的支持，有效解决传统相机在极端工况下性能退化或失效的问题 19。
深度学习与直接法的融合： 深度学习技术正在被广泛应用于视觉SLAM的各个环节，包括特征提取、深度估计、位姿回归以及鲁棒性增强等方面 20。虽然20主要讨论了深度学习在特征点法中的应用，但深度学习通过学习图像的复杂特征表示或直接回归位姿，有望提高直接法在复杂光照、弱纹理或动态环境下的鲁棒性和准确性 23。例如，利用卷积神经网络获得更稠密的2D-3D匹配点，并用于多阶段相机位姿估计 23。
多运动视觉里程计（MVO） 4、事件相机 19 和深度学习 20 等最新研究进展，体现了视觉SLAM领域持续的创新和对新传感器类型及人工智能范式的适应。事件相机能够克服传统相机在极端条件下的局限性，而深度学习则提供了从数据中学习复杂映射和鲁棒特征的能力。这些发展共同推动着直接法视觉里程计乃至整个SLAM领域向着更高精度、更强鲁棒性和更广适用性的方向迈进，以应对未来自动驾驶、机器人导航等应用中日益复杂的真实世界场景。
引用的著作
视觉SLAM是什么？一文带你快速了解视觉SLAM - 思岚科技, 访问时间为 八月 13, 2025， https://www.slamtec.com/en/News/Detail/237
视觉SLAM深度解读—新闻频道 - 视觉系统设计, 访问时间为 八月 13, 2025， https://www.vision-systems-china.com/deinews.asp?id=3135
The 6 Components of a Visual SLAM Algorithm - Think Autonomous, 访问时间为 八月 13, 2025， https://www.thinkautonomous.ai/blog/visual-slam/
多运动视觉里程计的方法与技术, 访问时间为 八月 13, 2025， http://gxbwk.njournal.sdu.edu.cn/CN/10.6040/j.issn.1672-3961.0.2020.382
毕业设计(论文)题目:视觉惯性组合定位里程计 - Wenliang GAO, 访问时间为 八月 13, 2025， https://gaowenliang.github.io/doc/gwl_thesis0.pdf
视觉里程计：特征点法之全面梳理 - 天池, 访问时间为 八月 13, 2025， https://tianchi.aliyun.com/forum/post/77433
基于点线特征融合的立体视觉里程计 - 光学仪器, 访问时间为 八月 13, 2025， https://joi.usst.edu.cn/html/2021/4/20210403.htm
python-visual-odometry/Chapter 11 - Visual Odometry Visual SLAM.ipynb at master - GitHub, 访问时间为 八月 13, 2025， https://github.com/polygon-software/python-visual-odometry/blob/master/Chapter%2011%20-%20Visual%20Odometry%20Visual%20SLAM.ipynb
ORB 特征- SLAM 之旅, 访问时间为 八月 13, 2025， https://lsxiang.github.io/Journey2SLAM/computer_vision/ORB/
融合光流法和特征匹配的视觉里程计 - Researching, 访问时间为 八月 13, 2025， https://www.researching.cn/ArticlePdf/m00002/2020/57/20/201501.pdf
视觉和激光雷达里程计紧耦合的SLAM 算法 - Researching, 访问时间为 八月 13, 2025， https://www.researching.cn/ArticlePdf/m00002/2023/60/14/1428006.pdf
特征点法SLAM视觉里程计自适应优化算法 - 系统仿真学报, 访问时间为 八月 13, 2025， https://www.china-simulation.com/CN/10.16182/j.issn1004731x.joss.20-0424E
SLAM入门之视觉里程计(1)：特征点的匹配 - 博客园, 访问时间为 八月 13, 2025， https://www.cnblogs.com/wangguchangqing/p/8076061.html
Develop Visual SLAM Algorithm Using Unreal Engine Simulation - MATLAB & Simulink, 访问时间为 八月 13, 2025， https://www.mathworks.com/help/driving/ug/develop-visual-slam-algorithm-using-unreal-engine-simulation.html
CN111882657B - 三维重建的尺度恢复方法、装置、系统和计算机设备 - Google Patents, 访问时间为 八月 13, 2025， https://patents.google.com/patent/CN111882657B/zh
CN111798505B - 一种基于单目视觉的三角化测量深度的稠密点云重建方法及系统, 访问时间为 八月 13, 2025， https://patents.google.com/patent/CN111798505B/zh
estimateFundamentalMatrix - Estimate fundamental matrix from ..., 访问时间为 八月 13, 2025， https://www.mathworks.com/help/vision/ref/estimatefundamentalmatrix.html
Mastering Fundamental Matrix in Robotics - Number Analytics, 访问时间为 八月 13, 2025， https://www.numberanalytics.com/blog/mastering-fundamental-matrix-in-robotics
机器人学院周易教授团队在神经形态视觉定位研究取得新进展, 访问时间为 八月 13, 2025， http://robotics.hnu.edu.cn/info/1035/3007.htm
基于深度学习特征点法的单目视觉里程计! - 计算机工程与科学, 访问时间为 八月 13, 2025， http://joces.nudt.edu.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=16250
gaoxiang12/slambook2: edition 2 of the slambook - GitHub, 访问时间为 八月 13, 2025， https://github.com/gaoxiang12/slambook2
gaoxiang12/slambook - GitHub, 访问时间为 八月 13, 2025， https://github.com/gaoxiang12/slambook
融合二维图像和三维点云的相机位姿估计 - 中国光学期刊网, 访问时间为 八月 13, 2025， https://www.opticsjournal.net/Articles/OJ83addc6a7b85b0c1/FullText
